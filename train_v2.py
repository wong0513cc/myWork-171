import os
import math
import json
import argparse
import random
from typing import Dict, Tuple, List
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import matplotlib.colors as mcolors            # æ–°å¢ï¼šé¡è‰²è½‰æ› HSVâ†’RGB

from model_test import ESGMultiModalModel
from dataset_v2 import GraphESGDataset

TARGET2IDX = {"env": 0, "soc": 1, "gov": 2}

# -------------------------------
# Utils
# -------------------------------

def set_seed(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

def smape(y_true, y_pred):
    y_true = np.asarray(y_true, dtype=np.float64)
    y_pred = np.asarray(y_pred, dtype=np.float64)
    denom = (np.abs(y_true) + np.abs(y_pred))
    denom[denom == 0] = 1.0
    return np.mean(np.abs(y_pred - y_true) / denom)

def pearsonr_safe(x, y):
    x = np.asarray(x).ravel()
    y = np.asarray(y).ravel()
    if x.size < 2 or y.size < 2:
        return np.nan
    xm = x - x.mean()
    ym = y - y.mean()
    denom = (np.linalg.norm(xm) * np.linalg.norm(ym))
    if denom == 0:
        return np.nan
    return float(np.dot(xm, ym) / denom)

def build_loaders(years_train, years_val, years_test, batch_size, root_paths, **kwargs):
    """å›å‚³ train/val/test ä¸‰å€‹ dictï¼Œæ¯å€‹ dict çš„ key æ˜¯å¹´ä»½ï¼Œvalue æ˜¯ DataLoader"""
    def make_loader(years, shuffle):
        loaders = {}
        for y in years:
            ds = GraphESGDataset(
                root_price=root_paths["price"],
                root_finance=root_paths["finance"],
                root_news=root_paths["news"],
                root_event=root_paths["event"],
                root_graph=root_paths["graph"],
                root_label=root_paths["label"],
                root_year_symbols=root_paths["year_symbols"],
                years=[y],
                has_label=True,
                strict_check=True,
                fill_missing_event="zeros",
                fill_missing_graph="zeros",
                **kwargs
            )
            # loaders[y] = DataLoader(ds, batch_size=batch_size, shuffle=shuffle, collate_fn=lambda x: x[0])
            loaders[y] = DataLoader(ds, batch_size=batch_size, shuffle=shuffle)
        return loaders
    train_loaders = make_loader(years_train, shuffle=True)
    val_loaders   = make_loader(years_val,   shuffle=False)
    test_loaders  = make_loader(years_test,  shuffle=False)
    return train_loaders, val_loaders, test_loaders

def select_labels_company_and_overall(label: torch.Tensor, target: str):
    """
    å›å‚³ï¼š
      - label_company: [B,1,N,1]ï¼ˆå¹´åº¦ã€é€å…¬å¸ï¼‰
      - label_overall: [B,1,1]  ï¼ˆå¹´åº¦ã€æ•´é«”ï¼‰
    """
    # æ•´åˆ° [B,K,N,C]
    if label.ndim == 2:       # [N,C]
        label = label.unsqueeze(0).unsqueeze(0)
    elif label.ndim == 3:     # [K,N,C]
        label = label.unsqueeze(0)
    elif label.ndim == 4:     # [B,K,N,C]
        pass
    else:
        raise ValueError(f"Unexpected label shape: {label.shape}")

    B, K, N, C = label.shape
    # å–é€šé“
    if target in {"env","soc","gov"}:
        ch = {"env":0,"soc":1,"gov":2}[target]
        lab = label[..., ch:ch+1] if C == 3 else label[..., 0:1]  # [B,K,N,1]
    else:
        lab = label.mean(dim=-1, keepdim=True) if C == 3 else label[..., 0:1]

    # å¹´åº¦èšåˆ
    lab_company = lab.mean(dim=1, keepdim=True)  # [B,1,N,1]ï¼ˆæ²¿ Kï¼‰
    lab_overall = lab_company.mean(dim=2, keepdim=True)  # [B,1,1,1]
    lab_overall = lab_overall.squeeze(2)  # [B,1,1]
    return lab_company, lab_overall

# -------------------------------
# Train/Eval
# -------------------------------

def move_inputs(batch: dict, device: torch.device, target: str):
    to = lambda t: (t.float().to(device) if isinstance(t, torch.Tensor) else t)
    price   = to(batch["price"]);   finance = to(batch["finance"])
    event   = to(batch["event"]);   news    = to(batch["news"])
    if price.ndim == 3: price = price.unsqueeze(0)
    if finance.ndim == 3: finance = finance.unsqueeze(0)
    if event.ndim == 3: event = event.unsqueeze(0)
    if news.ndim == 3: news = news.unsqueeze(0)

    bd = {"price":price, "finance":finance, "news":news, "event":event}
    if "label" in batch and batch["label"] is not None:
        lab = to(batch["label"])
        lab_company, lab_overall = select_labels_company_and_overall(lab, target)
        bd["label_company"] = lab_company.to(device)  # [B,1,N,1]
        bd["label_overall"] = lab_overall.to(device)  # [B,1,1]
    return bd


def train_one_epoch(model: nn.Module,
                    optimizer: optim.Optimizer,
                    loaders_by_year: Dict[int, DataLoader],
                    device: torch.device,
                    scaler: torch.cuda.amp.GradScaler,
                    epoch: int,
                    args) -> Dict[str, float]:
    model.train()
    log = {"loss_total":0.0,"mse":0.0,"ic_company":0.0,"steps":0}
    years = sorted(list(loaders_by_year.keys()))
    for y in years:
        for raw in loaders_by_year[y]:
            batch = move_inputs(raw, device, args.target)
            optimizer.zero_grad(set_to_none=True)
            with torch.cuda.amp.autocast(enabled=args.amp):
                out = model(batch)  # forward expects dict
                losses = out.get("losses", None)
                if losses is None:
                    raise RuntimeError("Model did not return 'losses' dict; ensure label is provided and loss enabled.")
                loss = losses["total"]

            # scaler.scale(loss).backward()
            # if args.grad_clip is not None and args.grad_clip > 0:
            #     scaler.unscale_(optimizer)
            #     torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
            # scaler.step(optimizer)
            # scaler.update()

            # ğŸ” åå‚³å‰æª¢æŸ¥ loss æ˜¯å¦æœ‰é™
            if not torch.isfinite(loss):
                print(f"[WARN] loss not finite at epoch {epoch}: {float(loss)}")

            # ğŸ” ç›£çœ‹ AMP scaleï¼ˆå‡ºç¾ inf/NaN æœƒä¸‹é™ã€ç”šè‡³è·³é stepï¼‰
            scale_before = scaler.get_scale()
            scaler.scale(loss).backward()
            if args.grad_clip is not None and args.grad_clip > 0:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
            scaler.step(optimizer)
            scaler.update()
            scale_after = scaler.get_scale()
            if scale_after < scale_before:
                print(f"[AMP] scale decreased {scale_before} -> {scale_after} (possible inf/NaN grads)")


            log["loss_total"] += float(loss.detach().item())
            log["mse"]        += float(losses["mse"].detach().item())
            log["ic_company"]         += float(losses["ic_company"].detach().item())
            log["steps"]      += 1

    for k in list(log.keys()):
        if k != "steps":
            log[k] = log[k] / max(1, log["steps"])
    return log

        
@torch.no_grad()
def evaluate(model: nn.Module,
             loaders_by_year: Dict[int, DataLoader],
             device: torch.device,
             args,
             desc="val") -> Tuple[Dict[str, float], Dict[int, dict]]:
    """
    è©•ä¼°ä½¿ç”¨ã€Œå…¬å¸å±¤ç´šã€ï¼š
      - å– pred_company [B,1,N,1] èˆ‡ label_company [B,1,N,1]
      - å°‡ B èˆ‡ N æ”¤å¹³æˆä¸€ç¶­ï¼Œå°æ‰€æœ‰å…¬å¸è¨ˆç®— mse/mae/rmse/smape
      - ic_company ä¹Ÿæ²¿å…¬å¸ç¶­åº¦è¨ˆç®—ï¼ˆpearson over all companies across yearsï¼‰
    per_year[y] æœƒå­˜è©²å¹´çš„ã€Œå…¬å¸å±¤ç´šã€å‘é‡ï¼ˆpreds/labels é•·åº¦ ~ N * Bï¼‰
    """
    model.eval()
    metrics = {"mse":0.0, "mae":0.0, "rmse":0.0, "smape":0.0, "ic_company": 0.0, "count":0}
    per_year = {}

    all_preds_company, all_labels_company = [], []

    years = sorted(list(loaders_by_year.keys()))
    for y in years:
        preds_y_list, labels_y_list = [], []
        symbols_y: List[str] = []

        for raw in loaders_by_year[y]:
            batch = move_inputs(raw, device, args.target)
            out = model(batch)

            # éœ€è¦å…¬å¸å±¤ç´šæ¨™ç±¤èˆ‡è¼¸å‡º
            if ("label_company" not in batch) or ("pred_company" not in out):
                continue

            pc = out["pred_company"].squeeze(1).squeeze(-1).detach().cpu().numpy()  # [B,N]
            lc = batch["label_company"].squeeze(1).squeeze(-1).detach().cpu().numpy()  # [B,N]

            # æ”¤å¹³æˆå‘é‡ï¼ˆB*Nï¼‰
            preds_y_list.append(pc.reshape(-1))
            labels_y_list.append(lc.reshape(-1))

            # ç›¡åŠ›å¾ raw å– symbolsï¼ˆbatch_size=1 æ™‚æœ€æº–ç¢ºï¼‰
            syms = raw.get("symbols", None)
            if syms is not None and len(symbols_y) == 0:
                # è‹¥ B>1ï¼Œé€™è£¡ä¸ä¸€å®šèƒ½æ‹¿åˆ°å…¨éƒ¨ symbolsï¼›å…ˆä¿å®ˆè™•ç†
                if isinstance(syms, list):
                    symbols_y = syms
                else:
                    try:
                        symbols_y = list(syms)
                    except Exception:
                        pass

        if len(preds_y_list) == 0:
            continue

        preds_y = np.concatenate(preds_y_list)   # [~B*N]
        labels_y = np.concatenate(labels_y_list)  # [~B*N]

        se_y  = (labels_y - preds_y) ** 2
        sse_y = float(se_y.sum())                # åŠ ç¸½ï¼ˆä½ è¦çš„ï¼‰
        mse_y = float(se_y.mean()) 

        mae_y = float(np.abs(labels_y - preds_y).mean())
        rmse_y = math.sqrt(mse_y)
        smape_y = float(np.mean(np.abs(preds_y - labels_y) /
                                (np.abs(labels_y) + np.abs(preds_y) + 1e-6)))
        ic_company_y = pearsonr_safe(labels_y, preds_y)

        # è¨˜éŒ„å¹´åº¦æ˜ç´°
        # symbols å°é½Šé•·åº¦ï¼šè‹¥ symbols_y é•·åº¦èˆ‡å…¬å¸æ•¸ä¸å°ï¼Œå°±çœç•¥ symbols
        per_year[y] = {
            "sse": sse_y, "mse": mse_y,
            "mae": mae_y,
            "rmse": rmse_y,
            "smape": smape_y,
            "ic_company": ic_company_y,
            "preds": preds_y, "labels": labels_y,
            "symbols": symbols_y if len(symbols_y) == preds_y.size else None
        }

        all_preds_company.append(preds_y)
        all_labels_company.append(labels_y)

    # åŒ¯ç¸½ï¼ˆæ‰€æœ‰å¹´ä»½ Ã— å…¬å¸ï¼‰
    if len(all_preds_company) > 0:
        all_preds_company = np.concatenate(all_preds_company)
        all_labels_company = np.concatenate(all_labels_company)

        mse = float(((all_labels_company - all_preds_company)**2).mean())
        mae = float(np.abs(all_labels_company - all_preds_company).mean())
        rmse = math.sqrt(mse)
        smape_all = float(np.mean(np.abs(all_preds_company - all_labels_company) /
                                  (np.abs(all_labels_company) + np.abs(all_preds_company) + 1e-6)))
        ic_company = pearsonr_safe(all_labels_company, all_preds_company)

        metrics.update({"mse":mse,"mae":mae,"rmse":rmse,"smape":smape_all,
                        "ic_company": ic_company, "count": all_preds_company.size})

    return metrics, per_year


def save_split_preds_labels(per_year: Dict[int, dict], out_path: str, split: str = "val", epoch: int = None):
    """
    æŠŠ evaluate å‚³å›çš„ per_year ä¸­çš„ preds/labels å­˜æˆä¸€å€‹ CSVã€‚
    æ¬„ä½ï¼šsplit, epoch, year, symbol, idx, pred, label
    - symbol è‹¥æ‹¿ä¸åˆ°å‰‡ç”¨ IDXi
    - idx æ˜¯è©²å¹´çš„å…¬å¸ç´¢å¼•ï¼ˆ0..N-1ï¼‰
    """
    rows = []
    for y, d in sorted(per_year.items()):
        preds = np.asarray(d["preds"])
        labels = np.asarray(d["labels"])
        symbols = d.get("symbols", None)
        n = len(preds)
        for i in range(n):
            sym = (symbols[i] if (symbols is not None and i < len(symbols)) else f"IDX{i}")
            rows.append({
                "split": split,
                "epoch": (int(epoch) if epoch is not None else None),
                "year": int(y),
                "symbol": sym,
                "idx": int(i),
                "pred": float(preds[i]),
                "label": float(labels[i]),
            })
    df = pd.DataFrame(rows, columns=["split","epoch","year","symbol","idx","pred","label"])
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    df.to_csv(out_path, index=False)
    return df


def plot_curves(history: dict, out_dir: str):
    epochs = np.arange(1, len(history.get("train", {}).get("loss_total", [])) + 1)
    if len(epochs) == 0:
        return

    # å–è³‡æ–™ï¼ˆå®‰å…¨å–ç”¨ï¼Œé¿å… KeyErrorï¼‰
    tr_total = history.get("train", {}).get("loss_total", [])
    val_mse  = history.get("val",   {}).get("mse", [])
    tr_ic    = history.get("train", {}).get("ic_company", [])
    val_ic   = history.get("val",   {}).get("ic_company", [])

    

    fig, ax1 = plt.subplots()

    # å·¦è»¸ï¼šLoss / MSE
    ax1.plot(epochs, tr_total, label="train_total", linewidth=2)
    if len(val_mse) == len(epochs) and len(val_mse) > 0:
        ax1.plot(epochs, val_mse, label="val_mse", linewidth=2)
    ax1.set_xlabel("Epoch")
    ax1.set_ylabel("Loss / MSE")
    ax1.set_title("Training & Validation")
    ax1.grid(True, alpha=0.25)

    # å³è»¸ï¼šICï¼ˆå…¬å¸å±¤ç´šï¼‰
    ax2 = ax1.twinx()
    has_any_ic = False
    if len(tr_ic) == len(epochs) and len(tr_ic) > 0:
        ax2.plot(epochs, tr_ic, "--", label="train_ic_company", linewidth=2)
        has_any_ic = True
    if len(val_ic) == len(epochs) and len(val_ic) > 0:
        ax2.plot(epochs, val_ic, "--", label="val_ic_company", linewidth=2)
        has_any_ic = True
    if has_any_ic:
        ax2.set_ylabel("IC (company-level)")

    # åˆä½µåœ–ä¾‹
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax1.legend(lines1 + lines2, labels1 + labels2, loc="best")

    fig.tight_layout()
    fig.savefig(out_dir, dpi=150)
    plt.close(fig)

def plot_scatter(pred: np.ndarray, label: np.ndarray, title: str, out_path: str):
    plt.figure()
    plt.scatter(label, pred, s=8, alpha=0.6)
    lo = float(min(label.min(), pred.min()))
    hi = float(max(label.max(), pred.max()))
    plt.plot([lo,hi], [lo,hi], linestyle='--')
    plt.xlabel("True")
    plt.ylabel("Pred")
    plt.title(title)
    plt.tight_layout()
    plt.savefig(out_path, dpi=150)
    plt.close()

def plot_scatter_from_year_detail(per_year: Dict[int, dict], title: str, out_path: str):
    if len(per_year) == 0:
        return
    years_sorted = sorted(per_year.keys())
    preds = np.concatenate([per_year[y]["preds"] for y in years_sorted])
    labels = np.concatenate([per_year[y]["labels"] for y in years_sorted])
    plot_scatter(preds, labels, title, out_path)

def colors_by_symbol(symbols: List[str]):
    """
    çµ¦æ¯å€‹ symbol ä¸€å€‹å›ºå®šé¡è‰²ï¼ˆè·¨åŸ·è¡Œä»ä¸€è‡´ï¼‰ã€‚
    å›å‚³ numpy array shape [len(symbols), 3] çš„ RGBã€‚
    """
    def _stable_hash(s: str) -> int:
        # FNV-1a 32-bit
        h = 2166136261
        for ch in s.encode("utf-8"):
            h = (h ^ ch) * 16777619
        return h & 0xffffffff

    hues = np.array([(_stable_hash(str(s)) % 360) / 360.0 for s in symbols], dtype=float)
    sat, val = 0.65, 0.85
    colors = [mcolors.hsv_to_rgb((h, sat, val)) for h in hues]
    return np.array(colors)

def sizes_by_rank(values: np.ndarray, base: float = 6.0, max_extra: float = 10.0):
    """
    å¯é¸ï¼šä¾é€£çºŒå€¼èª¿æ•´é»å¤§å°ï¼Œä¾‹å¦‚ä¾å¸‚å€¼/ESGåˆ†ä½ã€‚
    values: 1D arrayã€‚æœƒåšåˆ†ä½ç¸®æ”¾ï¼›è‹¥ä¸ç”¨å°±åˆ¥å‘¼å«ã€‚
    """
    if values is None or len(values) == 0:
        return None
    r = (values - values.min()) / (values.ptp() + 1e-8)
    return base + max_extra * r


def plot_modal_embeddings(model: nn.Module,
                          loaders_by_year: Dict[int, DataLoader],
                          device: torch.device,
                          args,
                          out_path: str,
                          year: int = None,
                          pool: str = "time",
                          max_points: int = 5000):
    """
    å¾æŸå€‹ validation/test å¹´ä»½æŠ“ä¸€å€‹ batchï¼Œå–å››æ¨¡æ…‹ encoder å¾Œçš„æ™‚é–“æ± åŒ– [B,N,H]ï¼Œ
    æ”¤å¹³æˆå…¬å¸é›†åˆï¼ˆB*N, Hï¼‰ï¼Œå„æ¨¡æ…‹å„è‡ªåš PCA 2Dï¼Œç•«åœ¨ 2x2 å­åœ–ã€‚
    """
    model.eval()
    years = sorted(list(loaders_by_year.keys()))
    if not years:
        print("[plot_modal_embeddings] no years in loader.")
        return
    y = year if (year is not None and year in years) else years[0]

    # å–ä¸€å€‹ batch
    raw = next(iter(loaders_by_year[y]))
    batch = move_inputs(raw, device, args.target)  # è½‰åˆ° [B,K,N,D] on device

    with torch.no_grad():
        enc = model.encode_modalities(batch, pool=pool)
        Pp = enc["pooled"]["price"]   # [B,N,H]
        Pf = enc["pooled"]["finance"]
        Pn = enc["pooled"]["news"]
        Pe = enc["pooled"]["event"]

        def _prep(X: torch.Tensor):
            X = X.detach().cpu().numpy()  # [B,N,H]
            X = X.reshape(-1, X.shape[-1])  # [B*N, H]
            if X.shape[0] > max_points:
                # éš¨æ©Ÿä¸‹æ¡æ¨£é¿å…é»å¤ªå¤š
                idx = np.random.choice(X.shape[0], max_points, replace=False)
                X = X[idx]
            return X

        Xp = _prep(Pp)
        Xf = _prep(Pf)
        Xn = _prep(Pn)
        Xe = _prep(Pe)

        def _pca2(x):
            if x.shape[0] < 3:
                # é»å¤ªå°‘æ™‚ï¼Œç°¡å–®è£œé›¶
                z = np.zeros((x.shape[0], 2), dtype=np.float32)
            else:
                z = PCA(n_components=2).fit_transform(x)
            return z
        
        # å–ä¸€å€‹ batch
        raw = next(iter(loaders_by_year[y]))
        batch = move_inputs(raw, device, args.target)  # è½‰åˆ° [B,K,N,D]

        # å–å¾—å…¬å¸æ¸…å–®ï¼ˆå°é½Š Nï¼‰ï¼Œå»ºè­°åœ¨é€™å€‹å¯è¦–åŒ–å‡½å¼å‘¼å«å‰ï¼Œå…ˆç”¨ batch_size=1
        symbols = raw.get("symbols", None)  # ä½ çš„ Dataset è‹¥æœ‰æä¾›ï¼Œé€šå¸¸é•·åº¦ = Nï¼›è‹¥æ²’æœ‰å¯ç•¥éä¸Šè‰²

        Zp = _pca2(Xp); Zf = _pca2(Xf); Zn = _pca2(Xn); Ze = _pca2(Xe)

 # æº–å‚™å°é½Šçš„é¡è‰²ï¼šåªå–ç¬¬ä¸€å€‹ batchï¼ˆå»ºè­° B=1ï¼‰ï¼ŒN å€‹é»
    color_map = None
    if isinstance(symbols, list):
        try:
            color_map = colors_by_symbol(symbols)  # shape [N, 3]
        except Exception:
            color_map = None

    # --- ç¹ªåœ– ---
    fig, axes = plt.subplots(2, 2, figsize=(10, 8))
    axlist = [axes[0,0], axes[0,1], axes[1,0], axes[1,1]]
    titles = ["Price (encoder)", "Finance (encoder)", "News (encoder)", "Event (encoder)"]
    data = [Zp, Zf, Zn, Ze]

    # æ³¨æ„ï¼šé€™è£¡å‡è¨­ä½ åœ¨ä¸Šé¢æ²’æœ‰å°é»åšä¸‹æ¡æ¨£ï¼Œä¸” B=1ï¼Œå‰‡ Zp.shape[0] æ‡‰è©² == N
    for ax, t, z in zip(axlist, titles, data):
        if z.shape[0] > 0:
            if (color_map is not None) and (len(color_map) == z.shape[0]):
                ax.scatter(z[:,0], z[:,1], s=8, c=color_map, alpha=0.9,
                           linewidths=0.2, edgecolors="k")
            else:
                ax.scatter(z[:,0], z[:,1], s=8, alpha=0.9, linewidths=0.2, edgecolors="k")
        ax.set_title(t)
        ax.set_xticks([]); ax.set_yticks([])
        ax.grid(True, alpha=0.15)

    fig.suptitle(f"Modal Encoders Embeddings (year={y}, pool={pool})")
    fig.tight_layout(rect=[0, 0.03, 1, 0.97])
    fig.savefig(out_path, dpi=150)
    plt.close(fig)
    print(f"[plot_modal_embeddings] saved to {out_path}")


def save_test_csv(per_year: Dict[int, dict], out_path: str):
    rows = []
    for y, d in per_year.items():
        preds = d["preds"]
        labels = d["labels"]
        symbols = d.get("symbols", None)
        for i in range(len(preds)):
            sym = (symbols[i] if (symbols is not None and i < len(symbols)) else f"IDX{i}")
            rows.append({"year": y, "symbol": sym, "pred": float(preds[i]), "label": float(labels[i])})
    df = pd.DataFrame(rows, columns=["year","symbol","pred","label"])
    df.to_csv(out_path, index=False)
    return df



def save_test_year_metrics(per_year: Dict[int, dict], years: List[int], out_path: str):
    """
    ä¾ per_yearï¼ˆevaluate å›å‚³ï¼‰èƒå–æŒ‡å®šå¹´ä»½çš„æŒ‡æ¨™ï¼Œå­˜æˆ CSVã€‚
    æ¬„ä½ï¼šyear, mse, rmse, mae, smape, ic
    è‹¥ per_year[y] æ²’æœ‰æŸæŒ‡æ¨™ï¼Œå°±ç”¨ preds/labels ç¾ç®—è£œä¸Šã€‚
    """
    rows = []
    for y in years:
        d = per_year.get(y)
        if d is None:
            continue

        # å…ˆå˜—è©¦æ‹¿ evaluate ç®—å¥½çš„å€¼
        mse   = d.get("mse",   None)
        mae   = d.get("mae",   None)
        rmse  = d.get("rmse",  None)
        smape = d.get("smape", None)
        ic    = d.get("ic_company", None)

        # å¦‚æœ‰ç¼ºæ¼ï¼Œç”¨ preds/labels ç¾ç®—
        preds  = d.get("preds",  None)
        labels = d.get("labels", None)
        if (preds is not None) and (labels is not None):
            preds  = np.asarray(preds)
            labels = np.asarray(labels)
            if mse   is None: mse   = float(((labels - preds) ** 2).mean())
            if mae   is None: mae   = float(np.abs(labels - preds).mean())
            if rmse  is None: rmse  = float(np.sqrt(((labels - preds) ** 2).mean()))
            if smape is None:
                smape = float(np.mean(np.abs(preds - labels) / (np.abs(labels) + np.abs(preds) + 1e-6)))
            if ic    is None:
                ic = pearsonr_safe(labels, preds)

        rows.append({
            "year": int(y),
            "mse": float(mse),
            "rmse": float(rmse),
            "mae": float(mae),
            "smape": float(smape),
            "ic": float(ic),
        })

    df = pd.DataFrame(rows, columns=["year","mse","rmse","mae","smape","ic"])
    df.to_csv(out_path, index=False)
    return df

# -------------------------------
# Main
# -------------------------------

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--target", type=str, default="esg", choices=["env","soc","gov","esg"])
    ap.add_argument("--epochs", type=int, default=50)
    ap.add_argument("--batch_size", type=int, default=4)
    ap.add_argument("--lr", type=float, default=1e-3)
    ap.add_argument("--weight_decay", type=float, default=1e-4)
    ap.add_argument("--grad_clip", type=float, default=1.0)
    ap.add_argument("--amp", action="store_true", default=False)
    ap.add_argument("--seed", type=int, default=42)
    ap.add_argument("--device", type=str, default="cuda")
    ap.add_argument("--logdir", type=str, default="runs")
    ap.add_argument("--out_dir", type=str, default="./outputs")
    ap.add_argument("--predict_yearly", action="store_true", default=True)
    ap.add_argument("--years_train", type=str, default="2015,2016,2017,2018,2019,2020")
    ap.add_argument("--years_val", type=str, default="2021,2022")
    ap.add_argument("--years_test", type=str, default="2023,2024")
    # data roots
    ap.add_argument("--root_price", type=str, required=True)
    ap.add_argument("--root_finance", type=str, required=True)
    ap.add_argument("--root_news", type=str, required=True)
    ap.add_argument("--root_event", type=str, required=True)
    ap.add_argument("--root_graph", type=str, required=True)
    ap.add_argument("--root_label", type=str, required=True)
    ap.add_argument("--root_year_symbols", type=str, required=True)
    args = ap.parse_args()

    set_seed(args.seed)
    os.makedirs(args.out_dir, exist_ok=True)

    device = torch.device(args.device if torch.cuda.is_available() else "cpu")

    root_paths = {
        "price": args.root_price,
        "finance": args.root_finance,
        "news": args.root_news,
        "event": args.root_event,
        "graph": args.root_graph,
        "label": args.root_label,
        "year_symbols": args.root_year_symbols,
    }

    years_train = [int(x) for x in args.years_train.split(",") if x.strip()]
    years_val   = [int(x) for x in args.years_val.split(",") if x.strip()]
    years_test  = [int(x) for x in args.years_test.split(",") if x.strip()]

    # loaders
    train_loaders, val_loaders, test_loaders = build_loaders(
        years_train, years_val, years_test, args.batch_size, root_paths
    )

    # å…ˆå¾ä¸€å€‹ batch æ¨æ–·å„æ¨¡æ…‹ç¶­åº¦ï¼Œå»ºç«‹æ¨¡å‹
    sample_year = years_train[0]
    sample_batch = next(iter(train_loaders[sample_year]))
    def _infer_dim(x):
        t = x if isinstance(x, torch.Tensor) else torch.tensor(x)
        if t.ndim == 3:  # [K,N,D]
            return t.shape[-1]
        elif t.ndim == 4:  # [B,K,N,D]
            return t.shape[-1]
        else:
            raise ValueError(f"Unexpected tensor ndim={t.ndim} for inferring D.")
    Dp = _infer_dim(sample_batch["price"])
    Df = _infer_dim(sample_batch["finance"])
    Dn = _infer_dim(sample_batch["news"])
    De = _infer_dim(sample_batch["event"])

    model = ESGMultiModalModel(
        d_price=Dp, d_finance=Df, d_news=Dn, d_event=De,
        hidden=64,
        lstm_layers=1, lstm_bidirectional=False,
        dropout=0.1,
        nhead_time=4,
        news_layers=2, event_layers=2,
        ic_weight=0.0, ic_type="pearson"
    ).to(device)

    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    scaler = torch.cuda.amp.GradScaler(enabled=args.amp)

    history = {
        "train": {"loss_total": [], "mse": [], "ic_company": []},
        "val": {"mse": [], "mae": [], "rmse": [], "smape": [], "ic_company": []},
    }

    best_val = float("inf")
    best_path = os.path.join(args.out_dir, f"best_esg_{args.target}.pth")

    for epoch in range(1, args.epochs + 1):
        tr_log = train_one_epoch(model, optimizer, train_loaders, device, scaler, epoch, args)
        history["train"]["loss_total"].append(tr_log["loss_total"])
        history["train"]["mse"].append(tr_log["mse"])
        history["train"]["ic_company"].append(tr_log["ic_company"])

        # é©—è­‰ï¼ˆä¸ç•«åœ–ï¼‰
        val_metrics, val_detail = evaluate(model, val_loaders, device, args, desc="val")
        for k in ["mse","mae","rmse","smape","ic_company"]:
            history["val"].setdefault(k, []).append(val_metrics.get(k, float("nan")))


        # â˜… æ–°å¢ï¼šå­˜é€™å€‹ epoch çš„ validation preds/labels
        val_csv_path = os.path.join(args.out_dir, f"val_preds_epoch{epoch:03d}_{args.target}.csv")
        _ = save_split_preds_labels(val_detail, out_path=val_csv_path, split="val", epoch=epoch)
        print(f"[VAL] Saved epoch {epoch} preds/labels to {val_csv_path}")

        # # --- Save best checkpoint (robust) ---
        # curr_mse = float(val_metrics.get("mse", float("inf")))

        # if not math.isfinite(curr_mse):
        #     print(f"[WARN] val MSE is not finite at epoch {epoch}: {curr_mse}")
        # else:
        #     improved = (curr_mse + 1e-9) < best_val  # min_delta é¿å…æµ®é»èª¤å·®
        #     if improved:
        #         best_val = curr_mse
        #         ckpt = {
        #             "epoch": epoch,
        #             "state_dict": model.state_dict(),
        #             "optimizer": optimizer.state_dict(),
        #             "val_mse": best_val,
        #         }
        #         try:
        #             ckpt["scaler"] = scaler.state_dict()
        #         except Exception:
        #             pass
        #         torch.save(ckpt, best_path)
        #         print(f"[BEST] epoch {epoch} improved: val_mse={curr_mse:.6f} â†’ saved to {best_path}")
        #     else:
        #         print(f"[BEST] no improve (best={best_val:.6f}, curr={curr_mse:.6f})")

        # # ï¼ˆå¯é¸ï¼‰æ¯å€‹ epoch éƒ½å­˜ä¸€ä»½ lastï¼Œæ–¹ä¾¿æ’æŸ¥åƒæ•¸æ˜¯å¦åœ¨å‹•
        # last_path = os.path.join(args.out_dir, f"last_esg_{args.target}.pth")
        # torch.save({
        #     "epoch": epoch,
        #     "state_dict": model.state_dict(),
        #     "optimizer": optimizer.state_dict(),
        #     "val_mse": curr_mse,
        # }, last_path)

        # å­˜æœ€å„ª
        if val_metrics["mse"] < best_val:
            best_val = val_metrics["mse"]
            torch.save({"epoch": epoch, "state_dict": model.state_dict(), "val_mse": best_val}, best_path)

        plot_curves(history, os.path.join(args.out_dir, f"curves_{args.target}.png"))
        print(
            f"Epoch {epoch:03d} | Train total {tr_log['loss_total']:.4f} "
            f"(mse {tr_log['mse']:.4f}, ic_company {tr_log['ic_company']:.4f}) | "
            f"Val MSE {val_metrics['mse']:.4f} RMSE {val_metrics['rmse']:.4f} "
            f"IC_company {val_metrics.get('ic_company', float('nan')):.4f}"
            f"SSE {val_metrics.get('sse', float('nan')):.1f} "
            f"IC_company {val_metrics.get('ic_company', float('nan')):.4f}"
        )
        
    print(f"[INFO] best_val after training = {best_val:.6f}")
    # Load best and plot once for VAL
    if os.path.isfile(best_path):
        ckpt = torch.load(best_path, map_location=device)
        model.load_state_dict(ckpt["state_dict"])
        print(f"Loaded best model from epoch {ckpt['epoch']} with val_mse={ckpt['val_mse']:.6f}")

    # å¯è¦–åŒ–ï¼šå››æ¨¡æ…‹ encoder embeddingsï¼ˆç”¨é©—è­‰é›†ç¬¬ä¸€å€‹å¹´ä»½çš„ä¸€å€‹ batchï¼‰
    plot_modal_embeddings(
        model, val_loaders, device, args,
        out_path=os.path.join(args.out_dir, f"modal_embeddings_{args.target}.png"),
        year=None,    # or years_val[0]
        pool="time",
        max_points=10**9  # ä¿è­‰ä¸ä¸‹æ¡æ¨£ï¼Œé¡è‰²æ‰èƒ½å°é½Š N
    )

    val_metrics, val_detail = evaluate(model, val_loaders, device, args, desc="val(best)")
    if len(val_detail) > 0:
        plot_scatter_from_year_detail(
            val_detail,
            title=f"Validation Scatter (best)",
            out_path=os.path.join(args.out_dir, f"val_scatter_{args.target}.png")
        )

    val_csv_path = os.path.join(args.out_dir, f"val_results_{args.target}.csv")
    _ = save_test_csv(val_detail, val_csv_path)
    print(f"Saved test CSV to {val_csv_path}")

    # TEST once
    test_metrics, test_detail = evaluate(model, test_loaders, device, args, desc="test")
    print("Test:", test_metrics)
    if len(test_detail) > 0:
        plot_scatter_from_year_detail(
            test_detail,
            title=f"Test Scatter (best)",
            out_path=os.path.join(args.out_dir, f"test_scatter_{args.target}.png")
        )

    csv_path = os.path.join(args.out_dir, f"test_results_{args.target}.csv")
    _ = save_test_csv(test_detail, csv_path)
    print(f"Saved test CSV to {csv_path}")

    year_csv_path = os.path.join(args.out_dir, f"test_year_metrics_{args.target}.csv")
    _ = save_test_year_metrics(test_detail, years=[2023, 2024], out_path=year_csv_path)
    print(f"Saved per-year test metrics CSV to {year_csv_path}")

    with open(os.path.join(args.out_dir, f"history_{args.target}.json"), "w") as f:
        json.dump(history, f, indent=2)

if __name__ == "__main__":
    main()
